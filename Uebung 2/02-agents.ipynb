{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligente Agenten\n",
    "Verwenden Sie ChatGPT um die untenstehenden Fragen zu beantworten! Wie stimmen die gegebenen Antworten mit ihrem aus der Vorlesung erlerntem Wissen überein?\n",
    "## Der Turing-Test\n",
    "1. Wie funktioniert der Turing-Test?\n",
    "2. Was braucht eine Maschine um den Test zu bestehen?\n",
    "3. Was ist der totale Turing-Test?\n",
    "4. Was braucht eine Maschine um den totalen Turing-Test zu bestehen?\n",
    "5. Welche Probleme existieren beim Turing-Test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenten\n",
    "1. Was ist ein Agent? Aus welchen Bestandteilen besteht ein Agent?\n",
    "2. Wenn man ChatGPT als Agent auffasst, wodurch werden die einzelne Bestandteile repräsentiert?\n",
    "3. Diskutieren Sie die folgenden Begriffe. Geben Sie jeweils 2 Beispiele für:<br/>\n",
    "    a) Vollständig beobachtbare Umgebung.          \n",
    "    b) Nichtdeterministische Umgebung.    \n",
    "    c) Single-Agent Umgebung.    \n",
    "    d) Multi-Agent Umgebung.    \n",
    "    e) Umgebung mit diskretem Zustandsraum.    \n",
    "    f) Umgebung mit kontinuierlichem Zustandsraum.    \n",
    "    g) Einfache Reflex-Agenten.    \n",
    "    h) Modellbasierte Reflex-Agenten.    \n",
    "    i) Zielbasierte Agenten.    \n",
    "    j) Lernfähige Agenten.    \n",
    "4. Was ist Rationalität?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Der Staubsauger als Agent\n",
    "Wir werden heute einen Staubsauger-Agenten und die dazugehörige Umgebung bzw. \"Welt\" programmieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst definieren wir uns eine Klasse \"Environment\". Diese Klasse repräsentiert unsere Welt in der sich der Agent bewegen soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \"\"\"Class representing an Environment. Other environment classes can\n",
    "    inherit from this. They typically need to implement:\n",
    "        percept:           Define the percept that an agent sees.\n",
    "        execute_action:    Define the effects of executing an action.\n",
    "                           Also update the agent.performance slot.\n",
    "    The environment keeps a dict of .loc_status which includes locations and their respective status. \n",
    "    There is also a list of .agents.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.loc_status = {(0, 0): random.choice(['Clean', 'Dirty']),\n",
    "                          (0, 1): random.choice(['Clean', 'Dirty']),\n",
    "                          (1, 0): random.choice(['Clean', 'Dirty']),\n",
    "                          (1, 1): random.choice(['Clean', 'Dirty'])}\n",
    "        self.agents = []\n",
    "        self.time = 0\n",
    "\n",
    "\n",
    "    def percept(self, agent):\n",
    "        \"\"\"Returns the agent's location, and the location status (Dirty/Clean).\"\"\"\n",
    "        return (agent.location, self.loc_status[agent.location])\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status\"\"\"\n",
    "        former_location = agent.location\n",
    "        if action == 'move_left' and agent.location[1] > 0:\n",
    "            agent.location = (agent.location[0], agent.location[1]-1)\n",
    "            print(f\"Moving left: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_right' and agent.location[1] < 1:\n",
    "            agent.location = (agent.location[0], agent.location[1]+1)\n",
    "            print(f\"Moving right: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_down' and agent.location[0] < 1:\n",
    "            agent.location = (agent.location[0]+1, agent.location[1])\n",
    "            print(f\"Moving down: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_up' and agent.location[0] > 0:\n",
    "            agent.location = (agent.location[0]-1, agent.location[1])\n",
    "            print(f\"Moving up: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'clean':\n",
    "            self.loc_status[agent.location] = 'Clean'\n",
    "            print(\"Cleaning: \", agent.location)\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'do_nothing':\n",
    "            print(\"Doing nothing at location:\", agent.location)\n",
    "            print(\"World state: \", self.loc_status)\n",
    "    \n",
    "\n",
    "    def default_location(self, thing):\n",
    "        \"\"\"Agents start in either location at random.\"\"\"\n",
    "        return random.choice([(0,0), (0,1), (1,0), (1,1)])\n",
    "\n",
    "    def exogenous_change(self):\n",
    "        \"\"\"If there is spontaneous change in the world, override this.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Run the environment for one time step. If the\n",
    "        actions and exogenous changes are independent, this method will\n",
    "        do. If there are interactions between them, you'll need to\n",
    "        override this method.\"\"\"\n",
    "        actions = []\n",
    "        \n",
    "        for agent in self.agents:\n",
    "            actions.append(agent.program(self.percept(agent)))\n",
    "        for (agent, action) in zip(self.agents, actions):\n",
    "            self.execute_action(agent, action)\n",
    "        self.exogenous_change()\n",
    "\n",
    "    def run(self, steps=10):\n",
    "        \"\"\"Run the Environment for given number of time steps.\"\"\"\n",
    "        print(\"Initial world state: \", self.loc_status)\n",
    "        for step in range(steps):\n",
    "            self.time += 1\n",
    "            self.step()\n",
    "            if all(value == \"Clean\" for value in self.loc_status.values()):\n",
    "                break\n",
    "\n",
    "    def add_agent(self, agent, location=None):\n",
    "        \"\"\"Add a thing to the environment, setting its location. For\n",
    "        convenience, if thing is an agent program we make a new agent\n",
    "        for it. (Shouldn't need to override this.)\"\"\"\n",
    "        if agent in self.agents:\n",
    "            print(\"Can't add the same agent twice\")\n",
    "        else:\n",
    "            agent.location = location if location is not None else self.default_location(agent)\n",
    "            self.agents.append(agent)\n",
    "\n",
    "    def delete_agent(self, agent):\n",
    "        \"\"\"Remove agent from the environment.\"\"\"\n",
    "        try:\n",
    "            self.agents.remove(agent)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            print(\"  in Environment delete_agent\")\n",
    "            print(\"  Agent to be removed: {} at {}\".format(agent, agent.location))\n",
    "            print(\"  from list: {}\".format([(agent, agent.location) for agent in self.agents]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann benötigen wir noch eine Klasse für unsere Agenten. Da wir im Laufe der Übung unterschiedliche Agenten implementieren möchten verwenden wir zunächst eine sogenannte \"abstrakte\" Klasse `TraceAgent`, von der unsere späteren konkreten Agent-Klassen erben können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TraceAgent:\n",
    "    \"\"\"An abstract class of an agent. Concrete agent classes wil inherit from this class and have to provide (at least) a program function.\n",
    "    Optionally you can also provide an __init__ function if the agent should have internal states.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loc_status = None\n",
    "        self.location = None\n",
    "        \n",
    "    def programm(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier sehen wir nun eine mögliche Implementierung einer `SimpleAgent`-Klasse. Dabei erbt diese Klasse alle Methoden und Attribute von der abstrakten Klasse `TraceAgent` und überschreibt diese gegebenenfalls mit ihrer eigenen Logik. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleAgent(TraceAgent):\n",
    "    def program(self, perception):\n",
    "        self.location, loc_status = perception\n",
    "        if loc_status == \"Clean\":\n",
    "            action = \"do_nothing\"\n",
    "        else:\n",
    "            action = \"clean\"\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun könnne wir uns mit folgender Zelle eine neue Welt erstellen und unseren `SimpleAgent`zu dieser Welt hinzufügen. Anschließend Simulieren wir 10 Zeitschritte in dieser Welt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = Environment()\n",
    "e.add_agent(SimpleAgent())\n",
    "e.run(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "Implementieren Sie die Klasse ReflexAgent als einfachen Reflex-Agenten. Das Verhalten können sie dabei selbst festlegen. Der Agent soll dabei in unserer Welt \"Environment\" funktionieren. Beachten Sie diesen Umstand bei der Festlegung möglicher Aktionen, die der Agent in der genannten Welt ausführen soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReflexAgent(TraceAgent):\n",
    "    def program(self, perception):\n",
    "        self.location, loc_status = perception\n",
    "        if loc_status == \"Clean\":\n",
    "            action = random.choice([\"move_left\", \"move_right\", \"move_up\", \"move_down\", \"do_nothing\"])\n",
    "        else:\n",
    "            action = \"clean\"\n",
    "        return action\n",
    "\n",
    "e1 = Environment()\n",
    "a1 = ReflexAgent()\n",
    "e1.add_agent(a1)\n",
    "e1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2\n",
    "Implementieren Sie die Klasse \"ModelBasedAgent\" als modellbasierten Agenten. Auch dieser Agent soll in der \"Environment\" funktionieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelBasedAgent(TraceAgent):\n",
    "    def __init__(self):\n",
    "        self.loc_status = {(0, 0): None,\n",
    "                           (0, 1): None,\n",
    "                           (1, 0): None,\n",
    "                           (1, 1): None}\n",
    "        self.location = None\n",
    "    def program(self, perception):\n",
    "        location, loc_status = perception\n",
    "        self.location = location\n",
    "        self.loc_status[self.location] = loc_status\n",
    "        \n",
    "        if self.loc_status[self.location] == \"Clean\":\n",
    "            # get all locations for which the agent knows that they are dirty or for which he has no information\n",
    "            dirty_places = [k for k,v in self.loc_status.items() if v == 'Dirty' or v is None]\n",
    "            if self.location[1] > 0 and self.loc_status[(self.location[0], self.location[1]-1)] in dirty_places:\n",
    "                action = \"move_left\"\n",
    "            elif self.location[1] < 1 and self.loc_status[(self.location[0], self.location[1]+1)] in dirty_places:\n",
    "                action = \"move_right\"\n",
    "            elif self.location[0] < 1 and self.loc_status[(self.location[0]+1, self.location[1])] in dirty_places:\n",
    "                action = \"move_down\"\n",
    "            elif self.location[0] > 0 and self.loc_status[(self.location[0]-1, self.location[1])] in dirty_places:\n",
    "                action = \"move_up\"\n",
    "            else:\n",
    "                action = random.choice([\"move_left\", \"move_right\", \"move_up\", \"move_down\"])\n",
    "        else:\n",
    "            action = \"clean\"\n",
    "            self.loc_status[self.location] = 'Clean'\n",
    "        return action\n",
    "\n",
    "e2 = Environment()\n",
    "a2 = ModelBasedAgent()\n",
    "e2.add_agent(a2)\n",
    "e2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 3\n",
    "Erweitern Sie die Implementierung der Environment, sodass es beliebig viele, auf einem 2D-Gitter angeordnete Positionen gibt. Erweitern Sie auch die Implementierung der beiden Agenten entsprechend, sodass diese sinnvoll in der neuen Umgebung agieren können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExtendedEnvironment(Environment):\n",
    "\n",
    "    \"\"\"This environment has nxn locations. Each can be Dirty\n",
    "    or Clean. The agent perceives its location and the location's\n",
    "    status. This serves as an example of how to implement a simple\n",
    "    Environment.\"\"\"\n",
    "\n",
    "    def __init__(self, grid_size: int):\n",
    "        super().__init__()\n",
    "        self.loc_status = {}\n",
    "        for i in range (grid_size):\n",
    "            for j in range (grid_size):\n",
    "                self.loc_status[(i,j)] = random.choice(['Clean', 'Dirty'])\n",
    "        self.max_coordinate = grid_size-1\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        \"\"\"Change agent's location and/or location's status\"\"\"\n",
    "        former_location = agent.location\n",
    "        if action == 'move_left' and agent.location[1] > 0:\n",
    "            agent.location = (agent.location[0], agent.location[1]-1)\n",
    "            print(f\"Moving left: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_right' and agent.location[1] < self.max_coordinate:\n",
    "            agent.location = (agent.location[0], agent.location[1]+1)\n",
    "            print(f\"Moving right: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_down' and agent.location[0] < self.max_coordinate:\n",
    "            agent.location = (agent.location[0]+1, agent.location[1])\n",
    "            print(f\"Moving down: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'move_up' and agent.location[0] > 0:\n",
    "            agent.location = (agent.location[0]-1, agent.location[1])\n",
    "            print(f\"Moving up: {former_location} -> {agent.location}\")\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'clean':\n",
    "            self.loc_status[agent.location] = 'Clean'\n",
    "            print(\"Cleaning: \", agent.location)\n",
    "            print(\"World state: \", self.loc_status)\n",
    "        elif action == 'do_nothing':\n",
    "            print(\"Doing nothing at location:\", agent.location)\n",
    "            print(\"World state: \", self.loc_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExtendedModelBasedAgent(TraceAgent):\n",
    "    def __init__(self, loc_status):\n",
    "        self.loc_status = dict.fromkeys(loc_status, None)\n",
    "        self.location = None\n",
    "    def program(self, perception):\n",
    "        location, loc_status = perception\n",
    "        self.location = location\n",
    "        self.loc_status[self.location] = loc_status\n",
    "        \n",
    "        if self.loc_status[self.location] == \"Clean\":\n",
    "            dirty_places = [k for k,v in self.loc_status.items() if v == 'Dirty']\n",
    "            if self.location[1] > 0 and self.loc_status[(self.location[0], self.location[1]-1)] in dirty_places:\n",
    "                action = \"move_left\"\n",
    "            elif self.location[1] < 1 and self.loc_status[(self.location[0], self.location[1]+1)] in dirty_places:\n",
    "                action = \"move_right\"\n",
    "            elif self.location[0] < 1 and self.loc_status[(self.location[0]+1, self.location[1])] in dirty_places:\n",
    "                action = \"move_down\"\n",
    "            elif self.location[0] > 0 and self.loc_status[(self.location[0]-1, self.location[1])] in dirty_places:\n",
    "                action = \"move_up\"\n",
    "            else:\n",
    "                action = random.choice([\"move_left\", \"move_right\", \"move_up\", \"move_down\"])\n",
    "        else:\n",
    "            action = \"clean\"\n",
    "            self.loc_status[self.location] = 'Clean'\n",
    "        return action\n",
    "\n",
    "e = ExtendedEnvironment(3)\n",
    "a = ExtendedModelBasedAgent(e.loc_status)\n",
    "e.add_agent(a)\n",
    "e.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
